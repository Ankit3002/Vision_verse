# -*- coding: utf-8 -*-
"""Ankit_vision.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11fPk5klyUJfkYZU_R_YfORZKCA0yYPjD
"""

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np
import os
os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/Colab Notebooks/'
import PIL
from skimage.io import imread
from skimage.transform import resize
from natsort import natsorted
from tensorflow import keras

DATADIR = '/content/drive/MyDrive/Colab Notebooks/data/train'
images= []
CATEGORIES = ['crownandrootrot' , 'healthywheat', 'leafrust', 'wheatloosesmut']

for i in CATEGORIES:
  num =0
  class_num = CATEGORIES.index(i) # label encoding the values
  path = os.path.join(DATADIR,i)  # create path to list all the images
  for img in natsorted(os.listdir(path)):
    img_array=imread(os.path.join(path,img))
    img_resized = resize(img_array,(150,150,3))  # this also normalize the data
    images.append(img_resized)
    num = num+1
    if(num == 547):
      break

x_train = np.array(images)   # x_train data

np.save('/content/drive/MyDrive/Colab Notebooks/train_548.npy', x_train) # to save the train data

y_train = []
for i in range(548):
  y_train.append(0)

for i in range(712):
  y_train.append(1)


for i in range(712):
  y_train.append(2)


for i in range(591):
  y_train.append(3)
y_train = np.array(y_train)     # y_train data

x_train = np.load('/content/drive/MyDrive/Colab Notebooks/file_name.npy')





from random import shuffle
from keras.models import model_from_json
ind_list = [i for i in range(len(x_train))]
shuffle(ind_list)
train_new  = x_train[ind_list, :,:,:]
target_new = y_train[ind_list,]
x_train = train_new
y_train = target_new    # to shuffle the train data

cnn = models.Sequential([
    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)),
    layers.MaxPooling2D((2, 2)),
    
    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])   # cnn model is build over here

cnn.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

cnn.fit(x_train, y_train, epochs=15)

DATADIR_test = '/content/drive/MyDrive/Colab Notebooks/data/test'    # directory of test data

# serialize model to JSON
model_json = cnn.to_json()
with open("/content/drive/MyDrive/Colab Notebooks/submission_model.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
cnn.save_weights("/content/drive/MyDrive/Colab Notebooks/model_last.h5")

images = []
for img in natsorted(os.listdir(DATADIR_test)):
    
    img_array=imread(os.path.join(DATADIR_test,img))
    img_resized = resize(img_array,(150,150,3))  # this also normalize the data
    images.append(img_resized)

x_test = np.array(images)    # to genrerate x_test data

y_pred = cnn.predict(x_test)   # prediction is done over here

y_classes = [np.argmax(element) for element in y_pred]    


import pandas as pd
col1 = []
col2 = []
for i in range(len(y_classes)):
  if(y_classes[i] == 0):
    col2.append('crownandrootrot')
  elif(y_classes[i] == 1):
    col2.append('healthywheat')
  elif(y_classes[i] == 2):
    col2.append('leafrust')
  else:
    col2.append('wheatloosesmut')

column_2 = np.array(col2)
for img in natsorted(os.listdir('/content/drive/MyDrive/Colab Notebooks/data/test')):
    
    col1.append(os.path.join('data/test',img))

column_1 = np.array(col1)

df = pd.DataFrame(column_2 , column_1)
df.to_csv('/content/drive/MyDrive/Colab Notebooks/LAst_sub.csv')

